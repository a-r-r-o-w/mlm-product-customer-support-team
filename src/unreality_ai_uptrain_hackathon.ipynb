{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed70a480-3686-4522-acee-ae48079579d2",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "  <a href=\"https://uptrain.ai\">\n",
    "    <img width=\"300\" src=\"https://user-images.githubusercontent.com/108270398/214240695-4f958b76-c993-4ddd-8de6-8668f4d0da84.png\" alt=\"uptrain\">\n",
    "  </a>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c074abda-7ad0-4af1-a7b4-f5177213dae8",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Fine-tuning a Large-Language Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f34304-dc81-4fd9-94dc-a7dfc371673a",
   "metadata": {},
   "source": [
    "### Install Required packages\n",
    "- [PyTorch](https://pytorch.org/get-started/locally/): Deep learning framework.\n",
    "- Hugging Face Transformers(https://huggingface.co/docs/transformers/installation): To use pretrained state-of-the-art models.\n",
    "- [Hugging Face Datasets](https://pypi.org/project/datasets/): Use public Hugging Face datasets\n",
    "- [IPywidgets](https://ipywidgets.readthedocs.io/en/stable/user_install.html): For interactive notebook widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52468837-a2f1-4531-bef5-b95276db6b82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/arrow/.local/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: transformers[torch] in /home/arrow/.local/lib/python3.10/site-packages (4.25.1)\n",
      "Requirement already satisfied: datasets in /home/arrow/.local/lib/python3.10/site-packages (2.9.0)\n",
      "Requirement already satisfied: ipywidgets in /home/arrow/.local/lib/python3.10/site-packages (8.0.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/arrow/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/arrow/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/arrow/.local/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/arrow/.local/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /home/arrow/.local/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.6.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers[torch]) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/arrow/.local/lib/python3.10/site-packages (from transformers[torch]) (1.23.3)\n",
      "Requirement already satisfied: filelock in /home/arrow/.local/lib/python3.10/site-packages (from transformers[torch]) (3.8.0)\n",
      "Requirement already satisfied: requests in /home/arrow/.local/lib/python3.10/site-packages (from transformers[torch]) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/arrow/.local/lib/python3.10/site-packages (from transformers[torch]) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/arrow/.local/lib/python3.10/site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/arrow/.local/lib/python3.10/site-packages (from transformers[torch]) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/arrow/.local/lib/python3.10/site-packages (from transformers[torch]) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/arrow/.local/lib/python3.10/site-packages (from transformers[torch]) (0.11.1)\n",
      "Requirement already satisfied: multiprocess in /home/arrow/.local/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/arrow/.local/lib/python3.10/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/arrow/.local/lib/python3.10/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/arrow/.local/lib/python3.10/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: pandas in /home/arrow/.local/lib/python3.10/site-packages (from datasets) (1.5.0)\n",
      "Requirement already satisfied: xxhash in /home/arrow/.local/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/arrow/.local/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /home/arrow/.local/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/arrow/.local/lib/python3.10/site-packages (from ipywidgets) (6.16.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /home/arrow/.local/lib/python3.10/site-packages (from ipywidgets) (4.0.3)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /home/arrow/.local/lib/python3.10/site-packages (from ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/arrow/.local/lib/python3.10/site-packages (from ipywidgets) (5.5.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/arrow/.local/lib/python3.10/site-packages (from ipywidgets) (8.5.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/arrow/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/arrow/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/arrow/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/arrow/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/arrow/.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/arrow/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/arrow/.local/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/arrow/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/arrow/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/arrow/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/arrow/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.4)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/arrow/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.1)\n",
      "Requirement already satisfied: nest-asyncio in /home/arrow/.local/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: pickleshare in /home/arrow/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /home/arrow/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/arrow/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.13.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/arrow/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/arrow/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /home/arrow/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.31)\n",
      "Requirement already satisfied: backcall in /home/arrow/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/arrow/.local/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/arrow/.local/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/arrow/.local/lib/python3.10/site-packages (from requests->transformers[torch]) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/arrow/.local/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/arrow/.local/lib/python3.10/site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/arrow/.local/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/arrow/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /home/arrow/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.11.2)\n",
      "Requirement already satisfied: entrypoints in /home/arrow/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/arrow/.local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/arrow/.local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=6.1.0->ipywidgets) (0.2.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: pure-eval in /home/arrow/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing in /home/arrow/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: asttokens in /home/arrow/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch 'transformers[torch]' datasets ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61005f8-27ae-4a7a-a190-fe5f335821cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from model_constants import *\n",
    "from model_train import retrain_model\n",
    "from helper_funcs import *\n",
    "import json\n",
    "import uptrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6e1263-e704-4de2-af99-507ea68125fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "testing_text = \"Nike shoes are very [MASK].\"\n",
    "original_model_outputs = test_model(model, testing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9edc5da-8366-4c55-93a7-4601c89c9970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  uptrain_smart_data_bert\n"
     ]
    }
   ],
   "source": [
    "def nike_text_present_func(inputs, outputs, gts=None, extra_args={}):\n",
    "    is_present = []\n",
    "    for input in inputs[\"text\"]:\n",
    "        this_present = \"nike\" in input.lower()\n",
    "        is_present.append(bool(this_present))\n",
    "    return is_present\n",
    "\n",
    "uptrain_save_fold_name = \"uptrain_smart_data_bert\"\n",
    "nike_text_present = uptrain.Signal(\"Nike Text Present\", nike_text_present_func)\n",
    "\n",
    "cfg = {\n",
    "    'checks': [{\n",
    "        'type': uptrain.Anomaly.EDGE_CASE,\n",
    "        \"signal_formulae\": nike_text_present\n",
    "    }],\n",
    "\n",
    "    # Define where to save the retraining dataset\n",
    "    'retraining_folder': uptrain_save_fold_name,\n",
    "    \n",
    "    # Define when to retrain, define a large number because we\n",
    "    # are not retraining yet\n",
    "    'retrain_after': 10000000000\n",
    "}\n",
    "\n",
    "framework = uptrain.Framework(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abe66970-c0ce-421d-9f7a-845453615903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  edge cases identified out of  197  total samples\n",
      "100  edge cases identified out of  397  total samples\n",
      "150  edge cases identified out of  597  total samples\n",
      "200  edge cases identified out of  797  total samples\n",
      "250  edge cases identified out of  997  total samples\n",
      "300  edge cases identified out of  1197  total samples\n",
      "350  edge cases identified out of  1397  total samples\n",
      "400  edge cases identified out of  1597  total samples\n",
      "450  edge cases identified out of  1797  total samples\n",
      "500  edge cases identified out of  1997  total samples\n",
      "550  edge cases identified out of  2197  total samples\n",
      "600  edge cases identified out of  2397  total samples\n",
      "650  edge cases identified out of  2597  total samples\n",
      "700  edge cases identified out of  2797  total samples\n",
      "750  edge cases identified out of  2997  total samples\n",
      "800  edge cases identified out of  3197  total samples\n",
      "850  edge cases identified out of  3397  total samples\n",
      "900  edge cases identified out of  3597  total samples\n",
      "950  edge cases identified out of  3797  total samples\n",
      "1000  edge cases identified out of  3997  total samples\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = create_sample_dataset(\"data.json\")\n",
    "with open(raw_dataset) as f:\n",
    "    all_data = json.load(f)\n",
    "\n",
    "for sample in all_data['data']:\n",
    "    inputs = {'data': {'text': [sample['text']]}}\n",
    "    framework.log(inputs = inputs, outputs = None)\n",
    "\n",
    "retraining_dataset = create_dataset_from_csv(uptrain_save_fold_name + \"/1/smart_data.csv\", \"text\", \"retrain_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d91d9-4540-4850-ad27-69fe9468e7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3bee747108b627eb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/arrow/.cache/huggingface/datasets/json/default-3bee747108b627eb/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057960a56dcf4001a12d881f6fdb7f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25577f0850f44ab9bfc6580c43907dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/arrow/.cache/huggingface/datasets/json/default-3bee747108b627eb/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed905eb2f81f48269be3f3b86efb4df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31c2d628a5c4690bf069fd4c5f37bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f8df9eb64d433db36584b255e69b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 64\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "retrain_model(model, retraining_dataset)\n",
    "retrained_model_outputs = test_model(model, testing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f014895c-0e6d-4886-a9b4-7071154e6315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print([original_model_outputs, retrained_model_outputs])\n",
    "\n",
    "# # Create Nike review training dataset\n",
    "# nike_attrs = {\n",
    "#     \"version\": \"0.1.0\",\n",
    "#     'source': \"nike review dataset\",\n",
    "#     'url': 'https://www.kaggle.com/datasets/tinkuzp23/nike-onlinestore-customer-reviews?resource=download',\n",
    "# }\n",
    "# # Download the dataset from the url, zip it and copy the csv file here\n",
    "# raw_nike_reviews_dataset = create_dataset_from_csv(\"web_scrapped.csv\", \"Content\", \"raw_nike_reviews_data.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
