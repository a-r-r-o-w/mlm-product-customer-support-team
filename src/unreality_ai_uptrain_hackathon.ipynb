{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed70a480-3686-4522-acee-ae48079579d2"
      },
      "source": [
        "<h1 align=\"center\">\n",
        "  <a href=\"https://uptrain.ai\">\n",
        "    <img width=\"300\" src=\"https://user-images.githubusercontent.com/108270398/214240695-4f958b76-c993-4ddd-8de6-8668f4d0da84.png\" alt=\"uptrain\">\n",
        "  </a>\n",
        "</h1>"
      ],
      "id": "ed70a480-3686-4522-acee-ae48079579d2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c074abda-7ad0-4af1-a7b4-f5177213dae8"
      },
      "source": [
        "<h1 style=\"text-align: center;\">Fine-tuning a Large-Language Model</h1>"
      ],
      "id": "c074abda-7ad0-4af1-a7b4-f5177213dae8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2f34304-dc81-4fd9-94dc-a7dfc371673a"
      },
      "source": [
        "### Install Required packages\n",
        "- [PyTorch](https://pytorch.org/get-started/locally/): Deep learning framework.\n",
        "- [Hugging Face Transformers](https://huggingface.co/docs/transformers/installation): To use pretrained state-of-the-art models.\n",
        "- [Hugging Face Datasets](https://pypi.org/project/datasets/): Use public Hugging Face datasets\n",
        "- [IPywidgets](https://ipywidgets.readthedocs.io/en/stable/user_install.html): For interactive notebook widgets\n",
        "- [UpTrain](https://github.com/uptrain-ai/uptrain): Use UpTrain to refine, monitor, check for distribution shifts and a whole lot more with your ML models"
      ],
      "id": "c2f34304-dc81-4fd9-94dc-a7dfc371673a"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52468837-a2f1-4531-bef5-b95276db6b82",
        "outputId": "211586ae-88b2-4412-ac26-3c534b9ca5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.8/dist-packages (0.16.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (7.7.1)\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.8/137.8 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: uptrain in /usr/local/lib/python3.8/dist-packages (0.0.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Requirement already satisfied: matplotlib==3.6.0 in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: torchview in /usr/local/lib/python3.8/dist-packages (0.2.5)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0) (1.21.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0) (4.38.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.0) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]) (0.13.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.3.4)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (7.9.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0\n",
            "  Downloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyterlab-widgets~=3.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.0.5)\n",
            "Requirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from uptrain) (1.10.4)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from uptrain) (5.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from uptrain) (1.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.4)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (57.4.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->uptrain) (8.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->uptrain) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[torch]) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[torch]) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[torch]) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[torch]) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->uptrain) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->uptrain) (1.7.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (5.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.6.2)\n",
            "Installing collected packages: widgetsnbextension, nltk, ipywidgets\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.1\n",
            "    Uninstalling widgetsnbextension-3.6.1:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed ipywidgets-8.0.4 nltk-3.8.1 widgetsnbextension-4.0.5\n",
            "mkdir: cannot create directory ‘datasets’: File exists\n",
            "mkdir: cannot create directory ‘datasets/raw’: File exists\n",
            "mkdir: cannot create directory ‘datasets/cleaned’: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --upgrade torch accelerate 'transformers[torch]' datasets ipywidgets uptrain nltk tqdm matplotlib==3.6.0 torchview\n",
        "!mkdir datasets datasets/raw datasets/cleaned"
      ],
      "id": "52468837-a2f1-4531-bef5-b95276db6b82"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f61005f8-27ae-4a7a-a190-fe5f335821cb"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import copy\n",
        "import json\n",
        "import math\n",
        "import nltk\n",
        "import random\n",
        "import string\n",
        "import torch\n",
        "import transformers\n",
        "import uptrain\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from accelerate import (\n",
        "  Accelerator\n",
        ")\n",
        "\n",
        "from datasets import (\n",
        "  load_dataset\n",
        ")\n",
        "\n",
        "from tqdm.auto import (\n",
        "  tqdm\n",
        ")\n",
        "\n",
        "from transformers import (\n",
        "  AutoModelForMaskedLM, AutoTokenizer,\n",
        "  DataCollatorForLanguageModeling, TrainingArguments, Trainer,\n",
        "  default_data_collator, get_scheduler, pipeline\n",
        ")\n",
        "\n",
        "from torch.optim import (\n",
        "  AdamW\n",
        ")\n",
        "\n",
        "from torch.utils.data import (\n",
        "  DataLoader\n",
        ")\n",
        "\n",
        "from torchview import draw_graph\n",
        "\n",
        "\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "# Removing imports to work without uploading files to Colab on every\n",
        "# new instance and instead copying the files as cells\n",
        "\n",
        "# from model_constants import *\n",
        "# from model_train import retrain_model\n",
        "# from helper_funcs import *"
      ],
      "id": "f61005f8-27ae-4a7a-a190-fe5f335821cb"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OdIgosNl4OG",
        "outputId": "f41e251a-8d8c-439f-82f1-6d7386d51f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Download the vader_lexicon package to use SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "id": "8OdIgosNl4OG"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yZN96c1rO6qt"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "chunk_size = 128\n",
        "wwm_probability = 0.2\n",
        "train_size = 0.9\n",
        "test_size = 0.1\n",
        "batch_size = 64\n",
        "mlm_probability = 0.15\n",
        "\n",
        "train_epochs = 2\n",
        "model_save_file_name = 'distilbert-base-uncased-finetuned-customer-product-support'"
      ],
      "id": "yZN96c1rO6qt"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K92jozn0Paad"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    result = tokenizer(examples[\"text\"])\n",
        "    if tokenizer.is_fast:\n",
        "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
        "    return result\n",
        "\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    # Compute length of concatenated texts\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the last chunk if it's smaller than chunk_size\n",
        "    total_length = (total_length // chunk_size) * chunk_size\n",
        "    # Split by chunks of max_len\n",
        "    result = {\n",
        "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    # Create a new labels column\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "def whole_word_masking_data_collator(features):\n",
        "    for feature in features:\n",
        "        word_ids = feature.pop(\"word_ids\")\n",
        "\n",
        "        # Create a map between words and corresponding token indices\n",
        "        mapping = collections.defaultdict(list)\n",
        "        current_word_index = -1\n",
        "        current_word = None\n",
        "        for idx, word_id in enumerate(word_ids):\n",
        "            if word_id is not None:\n",
        "                if word_id != current_word:\n",
        "                    current_word = word_id\n",
        "                    current_word_index += 1\n",
        "                mapping[current_word_index].append(idx)\n",
        "\n",
        "        # Randomly mask words\n",
        "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
        "        input_ids = feature[\"input_ids\"]\n",
        "        labels = feature[\"labels\"]\n",
        "        new_labels = [-100] * len(labels)\n",
        "        for word_id in np.where(mask)[0]:\n",
        "            word_id = word_id.item()\n",
        "            for idx in mapping[word_id]:\n",
        "                new_labels[idx] = labels[idx]\n",
        "                input_ids[idx] = tokenizer.mask_token_id\n",
        "        feature[\"labels\"] = new_labels\n",
        "    return default_data_collator(features)\n",
        "\n",
        "def test_model(model, text):\n",
        "    # The original line below doesn't work when using cuda as runtime and\n",
        "    # PyTorch throws a Runtime Error\n",
        "    # Setting the inputs device to 'cuda' fixes the issue\n",
        "\n",
        "    # inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to('cuda')\n",
        "    \n",
        "    token_logits = model(**inputs).logits\n",
        "    # Find the location of [MASK] and extract its logits\n",
        "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
        "    # Pick the [MASK] candidates with the highest logits\n",
        "    top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
        "    return [tokenizer.decode([token]) for token in top_5_tokens]\n",
        "\n",
        "def create_sample_dataset(save_file_name):\n",
        "    data = {\n",
        "        \"version\": \"0.1.0\",\n",
        "        \"source\": \"sample\",\n",
        "        \"url\": \"self-generated\",\n",
        "        \"data\": []\n",
        "    }\n",
        "    arr = []\n",
        "    random_words = [\"shoes\", \"jeans\", \"tshirts\", \"sweaters\", \"pants\", \"hoodies\", \"socks\", \"football\"]\n",
        "    for idx in range(1000):\n",
        "        arr.append({\"text\": \"Sample \" + str(100 * idx) + \" training sample - Nike \" + random.choice(random_words) + \" and \" + random.choice(random_words), \"label\": 0})\n",
        "        arr.append({\"text\": \"Sample \" + str(100 * idx) + \" training sample - Adidas \" + random.choice(random_words) + \" and \" + random.choice(random_words), \"label\": 0})\n",
        "        arr.append({\"text\": \"Sample \" + str(100 * idx) + \" training sample - Puma \" + random.choice(random_words) + \" and \" + random.choice(random_words), \"label\": 0})\n",
        "        arr.append({\"text\": \"Sample \" + str(100 * idx) + \" training sample - Bata \" + random.choice(random_words) + \" and \" + random.choice(random_words), \"label\": 0})\n",
        "    data[\"data\"] = arr\n",
        "\n",
        "    with open(save_file_name, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "    return save_file_name\n",
        "\n",
        "def create_dataset_from_csv(file_name, col_name, save_file_name, attrs={}):\n",
        "  data = pd.read_csv(file_name)\n",
        "  vals = list(data[col_name])\n",
        "  r_data = []\n",
        "  for val in vals:\n",
        "    try:\n",
        "      val = eval(val)\n",
        "    except:\n",
        "      pass\n",
        "    r_data.append({'text': str(val), 'label': 1})\n",
        "  json_data = attrs\n",
        "  json_data.update({\n",
        "      \"data\": r_data\n",
        "  })\n",
        "  with open(save_file_name, 'w') as f:\n",
        "      json.dump(json_data, f)\n",
        "  return save_file_name"
      ],
      "id": "K92jozn0Paad"
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCallback (transformers.TrainerCallback):\n",
        "  def __init__(self, trainer) -> None:\n",
        "    super().__init__()\n",
        "    self._trainer = trainer\n",
        "    self.outputs = []\n",
        "    \n",
        "  def on_step_end(self, args, state, control, **kwargs):\n",
        "    self.outputs.append(state)\n",
        "    if control.should_evaluate:\n",
        "      control_copy = copy.deepcopy(control)\n",
        "      self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
        "      return control_copy"
      ],
      "metadata": {
        "id": "qQV2vLT9_55s"
      },
      "id": "qQV2vLT9_55s",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tGVJglFcPVa-"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "def retrain_model(model, dataset, epochs=train_epochs, model_save_file_name=model_save_file_name):\n",
        "    retrain_dataset = load_dataset('json', data_files={\"train\": dataset}, field='data')\n",
        "    tokenized_datasets = retrain_dataset.map(\n",
        "      tokenize_function, batched=True, remove_columns=[\"text\", \"label\"]\n",
        "    )\n",
        "\n",
        "    lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=mlm_probability)\n",
        "\n",
        "    downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
        "      train_size=train_size, test_size=test_size, seed=42\n",
        "    )\n",
        "\n",
        "    # logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
        "    model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"{model_name}-finetuned-uptrain\",\n",
        "        overwrite_output_dir=True,\n",
        "        logging_strategy=\"steps\",\n",
        "        evaluation_strategy=\"steps\",\n",
        "        learning_rate=2e-5,\n",
        "        weight_decay=0.01,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        logging_steps=10,\n",
        "        eval_steps=2,\n",
        "        save_steps=10,\n",
        "        num_train_epochs=epochs\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=downsampled_dataset[\"train\"],\n",
        "        eval_dataset=downsampled_dataset[\"test\"],\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    training_outputs = CustomCallback(trainer)\n",
        "    trainer.add_callback(training_outputs)\n",
        "\n",
        "    before_eval_results = trainer.evaluate()\n",
        "    # print(f\">>> Before training, Perplexity: {math.exp(before_eval_results['eval_loss']):.2f}\")\n",
        "    print('Before Training Eval Results:\\n', json.dumps(before_eval_results, indent = 2))\n",
        "    print(f\"  Before Training Perplexity: {math.exp(before_eval_results['eval_loss']):.2f}\")\n",
        "\n",
        "    trainer_results = trainer.train()\n",
        "    trainer.save_model(model_save_file_name)\n",
        "\n",
        "    after_eval_results = trainer.evaluate()\n",
        "    # print(f\">>> After training, Perplexity: {math.exp(after_eval_results['eval_loss']):.2f}\")\n",
        "    print('After Training Eval Results:\\n', json.dumps(after_eval_results, indent = 2))\n",
        "    print(f\"  After Training Perplexity: {math.exp(after_eval_results['eval_loss']):.2f}\")\n",
        "\n",
        "    return (before_eval_results, after_eval_results, trainer_results, training_outputs, trainer)"
      ],
      "id": "tGVJglFcPVa-"
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_tokens (model, text, k = 5):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\").to('cuda')\n",
        "  token_logits = model(**inputs).logits\n",
        "  mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "  mask_token_logits = token_logits[0, mask_token_index, :]\n",
        "  top_k_tokens = torch.topk(mask_token_logits, k, dim=1).indices[0].tolist()\n",
        "  return [tokenizer.decode([token]) for token in top_k_tokens]"
      ],
      "metadata": {
        "id": "KvnwGZvfZCZ8"
      },
      "id": "KvnwGZvfZCZ8",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py407Se1cqyS"
      },
      "source": [
        "### Test using non-finetuned model to get an idea of basic mask-filling capability of distilbert-base-uncased"
      ],
      "id": "Py407Se1cqyS"
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_K = 10\n",
        "TESTING_TEXT = [\n",
        "  \"Nike shoes are very [MASK]\",\n",
        "  \"Nike atheletic wear is known for being very [MASK]\",\n",
        "  \"Nike [MASK] shoes are very comfortable\",\n",
        "  \"Trousers and Hoodies made by [MASK] are not very expensive\",\n",
        "  \"Nike tshirts are famous for being [MASK]\"\n",
        "]"
      ],
      "metadata": {
        "id": "BrsM_rKTZhEU"
      },
      "id": "BrsM_rKTZhEU",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aIVH_ismZZta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7bff7dc-d4ca-4b85-f300-dfd83d289654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"score\": 0.2500355839729309,\n",
            "    \"token\": 2759,\n",
            "    \"token_str\": \"popular\",\n",
            "    \"sequence\": \"nike shoes are very popular\"\n",
            "  },\n",
            "  {\n",
            "    \"score\": 0.15420399606227875,\n",
            "    \"token\": 25634,\n",
            "    \"token_str\": \"durable\",\n",
            "    \"sequence\": \"nike shoes are very durable\"\n",
            "  },\n",
            "  {\n",
            "    \"score\": 0.15004488825798035,\n",
            "    \"token\": 6450,\n",
            "    \"token_str\": \"expensive\",\n",
            "    \"sequence\": \"nike shoes are very expensive\"\n",
            "  },\n",
            "  {\n",
            "    \"score\": 0.030206406489014626,\n",
            "    \"token\": 6625,\n",
            "    \"token_str\": \"comfortable\",\n",
            "    \"sequence\": \"nike shoes are very comfortable\"\n",
            "  },\n",
            "  {\n",
            "    \"score\": 0.02582818642258644,\n",
            "    \"token\": 19964,\n",
            "    \"token_str\": \"fashionable\",\n",
            "    \"sequence\": \"nike shoes are very fashionable\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "unmasker = pipeline('fill-mask', model = model_checkpoint)\n",
        "print(json.dumps(unmasker(TESTING_TEXT[0]), indent = 2))"
      ],
      "id": "aIVH_ismZZta"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8d6e1263-e704-4de2-af99-507ea68125fd"
      },
      "outputs": [],
      "source": [
        "def get_model_and_tokenizer ():\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "  model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "  DEVICE = 'cpu'\n",
        "\n",
        "  print('Is \"cuda\" available?', torch.cuda.is_available())\n",
        "  if torch.cuda.is_available():\n",
        "    print('Device:', torch.cuda.get_device_name(0))\n",
        "    DEVICE = 'cuda'\n",
        "\n",
        "  # Assign to suppress output\n",
        "  _ = model.to(DEVICE)\n",
        "  return model, tokenizer"
      ],
      "id": "8d6e1263-e704-4de2-af99-507ea68125fd"
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = get_model_and_tokenizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvIPhm_KjXMc",
        "outputId": "54553f09-5a5d-4559-932f-d53986569778"
      },
      "id": "UvIPhm_KjXMc",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is \"cuda\" available? True\n",
            "Device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_graph = draw_graph(model, input_data=tokenizer(TESTING_TEXT[0], return_tensors=\"pt\").to('cuda'))\n",
        "model_graph.resize_graph(20)\n",
        "model_graph.visual_graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kN2_6-ju6Z3a",
        "outputId": "021264b4-30f3-471e-e448-5c1d4191d32e"
      },
      "id": "kN2_6-ju6Z3a",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fbc668997c0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: model Pages: 1 -->\n<svg width=\"656pt\" height=\"1200pt\"\n viewBox=\"0.00 0.00 656.00 1200.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1196)\">\n<title>model</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-1196 652,-1196 652,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"168.5,-1192 38.5,-1192 38.5,-1160 168.5,-1160 168.5,-1192\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"38.5,-1160 38.5,-1192 121.5,-1192 121.5,-1160 38.5,-1160\"/>\n<text text-anchor=\"start\" x=\"43.5\" y=\"-1179\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n<text text-anchor=\"start\" x=\"58.5\" y=\"-1168\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"121.5,-1160 121.5,-1192 168.5,-1192 168.5,-1160 121.5,-1160\"/>\n<text text-anchor=\"start\" x=\"126.5\" y=\"-1173.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7)</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"207,-1124 0,-1124 0,-1082 207,-1082 207,-1124\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-1082 0.5,-1124 65.5,-1124 65.5,-1082 0.5,-1082\"/>\n<text text-anchor=\"start\" x=\"5.5\" y=\"-1106\" font-family=\"Linux libertine\" font-size=\"10.00\">Embedding</text>\n<text text-anchor=\"start\" x=\"11.5\" y=\"-1095\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-1103 65.5,-1124 124.5,-1124 124.5,-1103 65.5,-1103\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-1111\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-1103 124.5,-1124 207.5,-1124 207.5,-1103 124.5,-1103\"/>\n<text text-anchor=\"start\" x=\"144.5\" y=\"-1111\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-1082 65.5,-1103 124.5,-1103 124.5,-1082 65.5,-1082\"/>\n<text text-anchor=\"start\" x=\"70.5\" y=\"-1090\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-1082 124.5,-1103 207.5,-1103 207.5,-1082 124.5,-1082\"/>\n<text text-anchor=\"start\" x=\"129.5\" y=\"-1090\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-1159.94C103.5,-1152.45 103.5,-1143.12 103.5,-1134.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-1134.16 103.5,-1124.16 100,-1134.16 107,-1134.16\"/>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"349.5,-885 219.5,-885 219.5,-853 349.5,-853 349.5,-885\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"219.5,-853 219.5,-885 302.5,-885 302.5,-853 219.5,-853\"/>\n<text text-anchor=\"start\" x=\"224.5\" y=\"-872\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n<text text-anchor=\"start\" x=\"239.5\" y=\"-861\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"302.5,-853 302.5,-885 349.5,-885 349.5,-853 302.5,-853\"/>\n<text text-anchor=\"start\" x=\"307.5\" y=\"-866.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7)</text>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"648,-812 351,-812 351,-770 648,-770 648,-812\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"351.5,-770 351.5,-812 458.5,-812 458.5,-770 351.5,-770\"/>\n<text text-anchor=\"start\" x=\"356.5\" y=\"-794\" font-family=\"Linux libertine\" font-size=\"10.00\">TransformerBlock</text>\n<text text-anchor=\"start\" x=\"383.5\" y=\"-783\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"458.5,-791 458.5,-812 517.5,-812 517.5,-791 458.5,-791\"/>\n<text text-anchor=\"start\" x=\"469.5\" y=\"-799\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"517.5,-791 517.5,-812 648.5,-812 648.5,-791 517.5,-791\"/>\n<text text-anchor=\"start\" x=\"522.5\" y=\"-799\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768), (1, 7) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"458.5,-770 458.5,-791 517.5,-791 517.5,-770 458.5,-770\"/>\n<text text-anchor=\"start\" x=\"463.5\" y=\"-778\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"517.5,-770 517.5,-791 648.5,-791 648.5,-770 517.5,-770\"/>\n<text text-anchor=\"start\" x=\"546.5\" y=\"-778\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 1&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>1&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M326.98,-852.98C357.29,-842.27 398.66,-827.65 433.28,-815.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"434.59,-818.66 442.86,-812.02 432.26,-812.06 434.59,-818.66\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"610,-734 313,-734 313,-692 610,-692 610,-734\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"313.5,-692 313.5,-734 420.5,-734 420.5,-692 313.5,-692\"/>\n<text text-anchor=\"start\" x=\"318.5\" y=\"-716\" font-family=\"Linux libertine\" font-size=\"10.00\">TransformerBlock</text>\n<text text-anchor=\"start\" x=\"345.5\" y=\"-705\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"420.5,-713 420.5,-734 479.5,-734 479.5,-713 420.5,-713\"/>\n<text text-anchor=\"start\" x=\"431.5\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"479.5,-713 479.5,-734 610.5,-734 610.5,-713 479.5,-713\"/>\n<text text-anchor=\"start\" x=\"484.5\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768), (1, 7) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"420.5,-692 420.5,-713 479.5,-713 479.5,-692 420.5,-692\"/>\n<text text-anchor=\"start\" x=\"425.5\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"479.5,-692 479.5,-713 610.5,-713 610.5,-692 479.5,-692\"/>\n<text text-anchor=\"start\" x=\"508.5\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 1&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>1&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M290.12,-852.85C298.6,-831.81 316.47,-793.68 342.5,-770 356.68,-757.1 374.36,-746.64 391.71,-738.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"393.64,-741.38 401.3,-734.06 390.75,-735 393.64,-741.38\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"572,-656 275,-656 275,-614 572,-614 572,-656\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"275.5,-614 275.5,-656 382.5,-656 382.5,-614 275.5,-614\"/>\n<text text-anchor=\"start\" x=\"280.5\" y=\"-638\" font-family=\"Linux libertine\" font-size=\"10.00\">TransformerBlock</text>\n<text text-anchor=\"start\" x=\"307.5\" y=\"-627\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"382.5,-635 382.5,-656 441.5,-656 441.5,-635 382.5,-635\"/>\n<text text-anchor=\"start\" x=\"393.5\" y=\"-643\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"441.5,-635 441.5,-656 572.5,-656 572.5,-635 441.5,-635\"/>\n<text text-anchor=\"start\" x=\"446.5\" y=\"-643\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768), (1, 7) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"382.5,-614 382.5,-635 441.5,-635 441.5,-614 382.5,-614\"/>\n<text text-anchor=\"start\" x=\"387.5\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"441.5,-614 441.5,-635 572.5,-635 572.5,-614 441.5,-614\"/>\n<text text-anchor=\"start\" x=\"470.5\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 1&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>1&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M281.65,-852.61C276.46,-819.71 269.02,-741.48 304.5,-692 314.03,-678.71 327.54,-668.47 342.07,-660.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"343.84,-663.64 351.21,-656.03 340.71,-657.38 343.84,-663.64\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"534,-578 237,-578 237,-536 534,-536 534,-578\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"237.5,-536 237.5,-578 344.5,-578 344.5,-536 237.5,-536\"/>\n<text text-anchor=\"start\" x=\"242.5\" y=\"-560\" font-family=\"Linux libertine\" font-size=\"10.00\">TransformerBlock</text>\n<text text-anchor=\"start\" x=\"269.5\" y=\"-549\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"344.5,-557 344.5,-578 403.5,-578 403.5,-557 344.5,-557\"/>\n<text text-anchor=\"start\" x=\"355.5\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"403.5,-557 403.5,-578 534.5,-578 534.5,-557 403.5,-557\"/>\n<text text-anchor=\"start\" x=\"408.5\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768), (1, 7) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"344.5,-536 344.5,-557 403.5,-557 403.5,-536 344.5,-536\"/>\n<text text-anchor=\"start\" x=\"349.5\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"403.5,-536 403.5,-557 534.5,-557 534.5,-536 403.5,-536\"/>\n<text text-anchor=\"start\" x=\"432.5\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 1&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M277.64,-852.75C259.91,-810.79 217.23,-691.64 266.5,-614 274.88,-600.79 287.29,-590.65 300.99,-582.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"302.89,-585.82 310.14,-578.09 299.65,-579.61 302.89,-585.82\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"496,-500 199,-500 199,-458 496,-458 496,-500\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"199.5,-458 199.5,-500 306.5,-500 306.5,-458 199.5,-458\"/>\n<text text-anchor=\"start\" x=\"204.5\" y=\"-482\" font-family=\"Linux libertine\" font-size=\"10.00\">TransformerBlock</text>\n<text text-anchor=\"start\" x=\"231.5\" y=\"-471\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"306.5,-479 306.5,-500 365.5,-500 365.5,-479 306.5,-479\"/>\n<text text-anchor=\"start\" x=\"317.5\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"365.5,-479 365.5,-500 496.5,-500 496.5,-479 365.5,-479\"/>\n<text text-anchor=\"start\" x=\"370.5\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768), (1, 7) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"306.5,-458 306.5,-479 365.5,-479 365.5,-458 306.5,-458\"/>\n<text text-anchor=\"start\" x=\"311.5\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"365.5,-458 365.5,-479 496.5,-479 496.5,-458 365.5,-458\"/>\n<text text-anchor=\"start\" x=\"394.5\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 1&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>1&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M270.91,-852.62C249.05,-826.23 208.5,-769.75 208.5,-714 208.5,-714 208.5,-714 208.5,-634 208.5,-589.55 201.03,-570.95 228.5,-536 239,-522.64 253.44,-512.32 268.66,-504.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"270.22,-507.53 277.68,-500 267.16,-501.24 270.22,-507.53\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"407,-422 110,-422 110,-380 407,-380 407,-422\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"110.5,-380 110.5,-422 217.5,-422 217.5,-380 110.5,-380\"/>\n<text text-anchor=\"start\" x=\"115.5\" y=\"-404\" font-family=\"Linux libertine\" font-size=\"10.00\">TransformerBlock</text>\n<text text-anchor=\"start\" x=\"142.5\" y=\"-393\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"217.5,-401 217.5,-422 276.5,-422 276.5,-401 217.5,-401\"/>\n<text text-anchor=\"start\" x=\"228.5\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"276.5,-401 276.5,-422 407.5,-422 407.5,-401 276.5,-401\"/>\n<text text-anchor=\"start\" x=\"281.5\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768), (1, 7) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"217.5,-380 217.5,-401 276.5,-401 276.5,-380 217.5,-380\"/>\n<text text-anchor=\"start\" x=\"222.5\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"276.5,-380 276.5,-401 407.5,-401 407.5,-380 276.5,-380\"/>\n<text text-anchor=\"start\" x=\"305.5\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 1&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>1&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M261.45,-852.99C247.11,-842.77 229.07,-828.19 216.5,-812 186.99,-774 170.5,-762.12 170.5,-714 170.5,-714 170.5,-714 170.5,-556 170.5,-511.63 166.68,-496.05 189.5,-458 196.26,-446.73 206.17,-436.75 216.38,-428.46\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"218.76,-431.04 224.57,-422.18 214.51,-425.49 218.76,-431.04\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"aliceblue\" stroke=\"transparent\" points=\"201,-1046 6,-1046 6,-1004 201,-1004 201,-1046\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"6.5,-1004 6.5,-1046 59.5,-1046 59.5,-1004 6.5,-1004\"/>\n<text text-anchor=\"start\" x=\"23.5\" y=\"-1028\" font-family=\"Linux libertine\" font-size=\"10.00\">add</text>\n<text text-anchor=\"start\" x=\"11.5\" y=\"-1017\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-1025 59.5,-1046 118.5,-1046 118.5,-1025 59.5,-1025\"/>\n<text text-anchor=\"start\" x=\"70.5\" y=\"-1033\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"118.5,-1025 118.5,-1046 201.5,-1046 201.5,-1025 118.5,-1025\"/>\n<text text-anchor=\"start\" x=\"123.5\" y=\"-1033\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-1004 59.5,-1025 118.5,-1025 118.5,-1004 59.5,-1004\"/>\n<text text-anchor=\"start\" x=\"64.5\" y=\"-1012\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"118.5,-1004 118.5,-1025 201.5,-1025 201.5,-1004 118.5,-1004\"/>\n<text text-anchor=\"start\" x=\"123.5\" y=\"-1012\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge2\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-1081.63C103.5,-1073.82 103.5,-1064.73 103.5,-1056.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-1056.16 103.5,-1046.16 100,-1056.16 107,-1056.16\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"207,-968 0,-968 0,-926 207,-926 207,-968\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-926 0.5,-968 65.5,-968 65.5,-926 0.5,-926\"/>\n<text text-anchor=\"start\" x=\"5.5\" y=\"-950\" font-family=\"Linux libertine\" font-size=\"10.00\">LayerNorm</text>\n<text text-anchor=\"start\" x=\"11.5\" y=\"-939\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-947 65.5,-968 124.5,-968 124.5,-947 65.5,-947\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-955\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-947 124.5,-968 207.5,-968 207.5,-947 124.5,-947\"/>\n<text text-anchor=\"start\" x=\"129.5\" y=\"-955\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-926 65.5,-947 124.5,-947 124.5,-926 65.5,-926\"/>\n<text text-anchor=\"start\" x=\"70.5\" y=\"-934\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-926 124.5,-947 207.5,-947 207.5,-926 124.5,-926\"/>\n<text text-anchor=\"start\" x=\"129.5\" y=\"-934\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge3\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-1003.63C103.5,-995.82 103.5,-986.73 103.5,-978.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-978.16 103.5,-968.16 100,-978.16 107,-978.16\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"201,-890 6,-890 6,-848 201,-848 201,-890\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"6.5,-848 6.5,-890 59.5,-890 59.5,-848 6.5,-848\"/>\n<text text-anchor=\"start\" x=\"11.5\" y=\"-872\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n<text text-anchor=\"start\" x=\"11.5\" y=\"-861\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-869 59.5,-890 118.5,-890 118.5,-869 59.5,-869\"/>\n<text text-anchor=\"start\" x=\"70.5\" y=\"-877\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"118.5,-869 118.5,-890 201.5,-890 201.5,-869 118.5,-869\"/>\n<text text-anchor=\"start\" x=\"123.5\" y=\"-877\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-848 59.5,-869 118.5,-869 118.5,-848 59.5,-848\"/>\n<text text-anchor=\"start\" x=\"64.5\" y=\"-856\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"118.5,-848 118.5,-869 201.5,-869 201.5,-848 118.5,-848\"/>\n<text text-anchor=\"start\" x=\"123.5\" y=\"-856\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge4\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-925.63C103.5,-917.82 103.5,-908.73 103.5,-900.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-900.16 103.5,-890.16 100,-900.16 107,-900.16\"/>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge5\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M201.13,-849.26C256.77,-838.58 326.79,-825.15 385.01,-813.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"385.83,-817.38 394.99,-812.06 384.51,-810.5 385.83,-817.38\"/>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge12\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M489.32,-769.63C485.28,-761.56 480.56,-752.12 476.17,-743.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"479.18,-741.54 471.58,-734.16 472.92,-744.67 479.18,-741.54\"/>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge13\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M451.32,-691.63C447.28,-683.56 442.56,-674.12 438.17,-665.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"441.18,-663.54 433.58,-656.16 434.92,-666.67 441.18,-663.54\"/>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge14\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M413.32,-613.63C409.28,-605.56 404.56,-596.12 400.17,-587.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"403.18,-585.54 395.58,-578.16 396.92,-588.67 403.18,-585.54\"/>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge15\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M375.32,-535.63C371.28,-527.56 366.56,-518.12 362.17,-509.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"365.18,-507.54 357.58,-500.16 358.92,-510.67 365.18,-507.54\"/>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge16\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M323.65,-457.63C313.29,-448.79 301.01,-438.3 289.93,-428.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"291.99,-425.99 282.11,-422.16 287.44,-431.31 291.99,-425.99\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"356,-344 161,-344 161,-302 356,-302 356,-344\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"161.5,-302 161.5,-344 214.5,-344 214.5,-302 161.5,-302\"/>\n<text text-anchor=\"start\" x=\"169.5\" y=\"-326\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"166.5\" y=\"-315\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"214.5,-323 214.5,-344 273.5,-344 273.5,-323 214.5,-323\"/>\n<text text-anchor=\"start\" x=\"225.5\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"273.5,-323 273.5,-344 356.5,-344 356.5,-323 273.5,-323\"/>\n<text text-anchor=\"start\" x=\"278.5\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"214.5,-302 214.5,-323 273.5,-323 273.5,-302 214.5,-302\"/>\n<text text-anchor=\"start\" x=\"219.5\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"273.5,-302 273.5,-323 356.5,-323 356.5,-302 273.5,-302\"/>\n<text text-anchor=\"start\" x=\"278.5\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge17\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M258.5,-379.63C258.5,-371.82 258.5,-362.73 258.5,-354.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"262,-354.16 258.5,-344.16 255,-354.16 262,-354.16\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"377,-266 140,-266 140,-224 377,-224 377,-266\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"140.5,-224 140.5,-266 235.5,-266 235.5,-224 140.5,-224\"/>\n<text text-anchor=\"start\" x=\"145.5\" y=\"-248\" font-family=\"Linux libertine\" font-size=\"10.00\">GELUActivation</text>\n<text text-anchor=\"start\" x=\"166.5\" y=\"-237\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"235.5,-245 235.5,-266 294.5,-266 294.5,-245 235.5,-245\"/>\n<text text-anchor=\"start\" x=\"246.5\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"294.5,-245 294.5,-266 377.5,-266 377.5,-245 294.5,-245\"/>\n<text text-anchor=\"start\" x=\"299.5\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"235.5,-224 235.5,-245 294.5,-245 294.5,-224 235.5,-224\"/>\n<text text-anchor=\"start\" x=\"240.5\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"294.5,-224 294.5,-245 377.5,-245 377.5,-224 294.5,-224\"/>\n<text text-anchor=\"start\" x=\"299.5\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge18\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M258.5,-301.63C258.5,-293.82 258.5,-284.73 258.5,-276.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"262,-276.16 258.5,-266.16 255,-276.16 262,-276.16\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"362,-188 155,-188 155,-146 362,-146 362,-188\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"155.5,-146 155.5,-188 220.5,-188 220.5,-146 155.5,-146\"/>\n<text text-anchor=\"start\" x=\"160.5\" y=\"-170\" font-family=\"Linux libertine\" font-size=\"10.00\">LayerNorm</text>\n<text text-anchor=\"start\" x=\"166.5\" y=\"-159\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"220.5,-167 220.5,-188 279.5,-188 279.5,-167 220.5,-167\"/>\n<text text-anchor=\"start\" x=\"231.5\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"279.5,-167 279.5,-188 362.5,-188 362.5,-167 279.5,-167\"/>\n<text text-anchor=\"start\" x=\"284.5\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"220.5,-146 220.5,-167 279.5,-167 279.5,-146 220.5,-146\"/>\n<text text-anchor=\"start\" x=\"225.5\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"279.5,-146 279.5,-167 362.5,-167 362.5,-146 279.5,-146\"/>\n<text text-anchor=\"start\" x=\"284.5\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge19\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M258.5,-223.63C258.5,-215.82 258.5,-206.73 258.5,-198.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"262,-198.16 258.5,-188.16 255,-198.16 262,-198.16\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"362,-110 155,-110 155,-68 362,-68 362,-110\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"155.5,-68 155.5,-110 208.5,-110 208.5,-68 155.5,-68\"/>\n<text text-anchor=\"start\" x=\"163.5\" y=\"-92\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"160.5\" y=\"-81\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"208.5,-89 208.5,-110 267.5,-110 267.5,-89 208.5,-89\"/>\n<text text-anchor=\"start\" x=\"219.5\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"267.5,-89 267.5,-110 362.5,-110 362.5,-89 267.5,-89\"/>\n<text text-anchor=\"start\" x=\"278.5\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 768) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"208.5,-68 208.5,-89 267.5,-89 267.5,-68 208.5,-68\"/>\n<text text-anchor=\"start\" x=\"213.5\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"267.5,-68 267.5,-89 362.5,-89 362.5,-68 267.5,-68\"/>\n<text text-anchor=\"start\" x=\"272.5\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 30522) </text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge20\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M258.5,-145.63C258.5,-137.82 258.5,-128.73 258.5,-120.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"262,-120.16 258.5,-110.16 255,-120.16 262,-120.16\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"347.5,-32 169.5,-32 169.5,0 347.5,0 347.5,-32\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"169.5,0 169.5,-32 258.5,-32 258.5,0 169.5,0\"/>\n<text text-anchor=\"start\" x=\"174.5\" y=\"-19\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n<text text-anchor=\"start\" x=\"192.5\" y=\"-8\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"258.5,0 258.5,-32 347.5,-32 347.5,0 258.5,0\"/>\n<text text-anchor=\"start\" x=\"263.5\" y=\"-13.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 7, 30522)</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge21\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M258.5,-67.84C258.5,-59.89 258.5,-50.66 258.5,-42.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"262,-42.24 258.5,-32.24 255,-42.24 262,-42.24\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRODUCTS = [\n",
        "  'gym wear', 'jackets', 'shirts',\n",
        "  'running shoes', 'basketballs', 'caps', 'pants', 'socks',\n",
        "  'trousers', 'training shoes', 'basketball shoes', 'shoes',\n",
        "  'athletic wear', 'sports wear', 'footballs',\n",
        "  'performance gear', 'hats', 'sweaters', 'tshirts', 'wristbands',\n",
        "  'backpacks', 'tshirts', 'hoodies', 'trainers',\n",
        "  'soccer shoes',\n",
        "]\n",
        "\n",
        "POSITIVE_SENTIMENT_ADJECTIVES = [\n",
        "  'stylish', 'innovative', 'comfortable', 'durable', 'performance-oriented',\n",
        "  'high-quality', 'fashionable', 'sporty', 'functional', 'lightweight',\n",
        "  'breathable', 'flexible', 'athletic', 'modern', 'inexpensive', 'cheap',\n",
        "  'trendsetting', \"revolutionary\", 'good-looking'\n",
        "]\n",
        "\n",
        "NEGATIVE_SENTIMENT_ADJECTIVES = [\n",
        "  'uncomfortable', 'flimsy', 'poor quality', 'outdated', 'unfashionable',\n",
        "  'heavy', 'inferior', 'unathletic', 'expensive', 'costly',\n",
        "  'overpriced', 'defective', 'ugly', 'dirty', 'faulty'\n",
        "]\n",
        "\n",
        "ADJECTIVES = POSITIVE_SENTIMENT_ADJECTIVES + NEGATIVE_SENTIMENT_ADJECTIVES\n",
        "\n",
        "PRODUCT_FEATURE_WORDS = list(set(\n",
        "  ['comfort', 'fit', 'quality', 'style', 'durability', 'performance', 'design', 'look', 'support', 'flexibility', 'lightweight', 'breathability', 'cushioning', 'grip', 'stability', 'traction', 'bounce'] +\n",
        "  POSITIVE_SENTIMENT_ADJECTIVES\n",
        "))\n",
        "\n",
        "COMPANIES = [\n",
        "  # repeat a couple of times for higher positive examples\n",
        "  'nike', 'nike', 'nike', 'nike', 'nike', 'nike', 'nike'\n",
        "  'adidas', 'puma', 'under armour', 'new balance', 'reebok',\n",
        "  'converse', 'vans', 'fila', 'asics'\n",
        "]\n",
        "\n",
        "JOINERS = [\n",
        "  'are', 'is', 'offer', 'provide', 'feature', 'boast',\n",
        "  'are known for being', 'are recognized for being', 'are famous for being',\n",
        "  'are renowned for being', 'are praised for being',\n",
        "]"
      ],
      "metadata": {
        "id": "JPng63acejQ6"
      },
      "id": "JPng63acejQ6",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5oBrUFJlvuSM"
      },
      "outputs": [],
      "source": [
        "def csv2json (csv_file_name, json_file_name, attrs={}):\n",
        "  df = pd.read_csv(csv_file_name)\n",
        "  data = []\n",
        "  \n",
        "  for _, row in df.iterrows():\n",
        "    print(row.to_dict())\n",
        "    data.append({\n",
        "      'text': row['text'],\n",
        "      'label': row['label']\n",
        "    })\n",
        "  \n",
        "  json_data = attrs\n",
        "  json_data.update({'data': data})\n",
        "\n",
        "  with open(json_file_name, 'w') as f:\n",
        "    json.dump(json_data, f)\n",
        "\n",
        "def create_basic_brute_dataset(dataset_size):\n",
        "  data = {\n",
        "      \"version\": \"0.1.0\",\n",
        "      \"source\": \"sample\",\n",
        "      \"url\": \"self-generated\",\n",
        "      \"data\": []\n",
        "  }\n",
        "  arr = []\n",
        "\n",
        "  for idx in range(dataset_size):\n",
        "    company = random.choice(COMPANIES)\n",
        "    joiner = random.choice(JOINERS)\n",
        "    product = random.choice(PRODUCTS)\n",
        "    label = random.choice([0, 1])\n",
        "    \n",
        "    if label == 0:\n",
        "      adjective = random.choice(NEGATIVE_SENTIMENT_ADJECTIVES)\n",
        "    else:\n",
        "      adjective = random.choice(POSITIVE_SENTIMENT_ADJECTIVES)\n",
        "    \n",
        "    sentence = f'{company} {product} {joiner} {adjective}'\n",
        "    \n",
        "    arr.append({\n",
        "      \"text\": sentence,\n",
        "      \"label\": label\n",
        "    })\n",
        "  \n",
        "  data[\"data\"] = arr\n",
        "  return data\n",
        "\n",
        "def save_dataset (dataset, save_file_name):\n",
        "  with open(save_file_name, 'w') as f:\n",
        "    json.dump(dataset, f)"
      ],
      "id": "5oBrUFJlvuSM"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "soATfYH44Rfd"
      },
      "outputs": [],
      "source": [
        "SYNTHESIZED_DATASET_SIZE = 10000\n",
        "uptrain_save_fold_name = \"uptrain_smart_data_bert\"\n",
        "synthesized_data_csv = 'data.csv'\n",
        "synthesized_data_file_name = 'data.json'\n",
        "\n",
        "nike_products_dataset = {\n",
        "  'version': \"1.0.0\",\n",
        "  'source': \"Product Data from Nike\",\n",
        "  'url': \"https://data.world/data-hut/product-data-from-nike\",\n",
        "  'infile': \"datasets/raw/nike_products.csv\",\n",
        "  'outfile': \"datasets/cleaned/nike_products.json\"\n",
        "}\n",
        "\n",
        "nike_customer_reviews_kaggle_dataset = {\n",
        "  'version': \"1.0.0\",\n",
        "  'source': \"Nike Onlinestore Customer Reviews\",\n",
        "  'url': \"https://www.kaggle.com/datasets/tinkuzp23/nike-onlinestore-customer-reviews\",\n",
        "  'infile': \"datasets/raw/nike_customer_reviews_kaggle.csv\",\n",
        "  'outfile': \"datasets/cleaned/nike_customer_reviews_kaggle.json\"\n",
        "}\n",
        "\n",
        "products_kaggle_dataset = {\n",
        "  'version': \"1.0.0\",\n",
        "  'source': \"Products: Prices, Descriptions, Reviews\",\n",
        "  'url': \"https://www.kaggle.com/datasets/thedevastator/nike-usa-products-prices-descriptions-and-custom\",\n",
        "  'infile': \"datasets/raw/products_kaggle.csv\",\n",
        "  'outfile': \"datasets/cleaned/products_kaggle.json\"\n",
        "}"
      ],
      "id": "soATfYH44Rfd"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "# Use the nike_products dataset and append it to our dataframe\n",
        "nike_products_df = pd.read_csv(nike_products_dataset['infile'])\n",
        "x = pd.DataFrame()\n",
        "x['text'] = nike_products_df['Product Name'] + ' ' + nike_products_df['Description']\n",
        "x.reset_index(drop=True, inplace=True)\n",
        "x.to_json(nike_products_dataset['outfile'])\n",
        "df = x\n",
        "\n",
        "# Use the nike_customer_reviews dataset and append it to our dataframe\n",
        "nike_customer_reviews_kaggle_df = pd.read_csv(nike_customer_reviews_kaggle_dataset['infile'])\n",
        "x = pd.DataFrame()\n",
        "x['text'] = nike_customer_reviews_kaggle_df['Title'] + ' ' + nike_customer_reviews_kaggle_df['Content']\n",
        "x.reset_index(drop=True, inplace=True)\n",
        "x.to_json(nike_customer_reviews_kaggle_dataset['outfile'])\n",
        "df = df.append(x)\n",
        "\n",
        "# Use the products_kaggle dataset and append it to our dataframe\n",
        "products_kaggle_df = pd.read_csv(products_kaggle_dataset['infile'])\n",
        "x = pd.DataFrame()\n",
        "x['text'] = products_kaggle_df['name'] + ' ' + products_kaggle_df['description']\n",
        "x.reset_index(drop=True, inplace=True)\n",
        "x.to_json(products_kaggle_dataset['outfile'])\n",
        "df = df.append(x)\n",
        "\n",
        "df = df[df['text'].notna()]\n",
        "\n",
        "# Replace all raw digits because they're most likely of no use in determining\n",
        "# masked words\n",
        "df['text'] = df['text'].apply(lambda x: x.translate(str.maketrans('', '', string.digits)))\n",
        "\n",
        "# Remove all punctuation explicitly even though BERT probably does it\n",
        "df['text'] = df['text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Create our own dataset of reviews for different companies, products, etc.\n",
        "brute_dataset = create_basic_brute_dataset(SYNTHESIZED_DATASET_SIZE)\n",
        "brute_df = pd.DataFrame(brute_dataset['data'])\n",
        "df = df.append(brute_df)\n",
        "\n",
        "# Make everything lowercase since the model is uncased\n",
        "df['text'] = df['text'].str.lower()\n",
        "\n",
        "print(f'Dataset size: {len(df)}')\n",
        "print(df)\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.to_csv(synthesized_data_csv)\n",
        "create_dataset_from_csv(synthesized_data_csv, 'text', synthesized_data_file_name)\n",
        "\n",
        "with open(synthesized_data_file_name) as file:\n",
        "  dataset = json.loads(file.read())"
      ],
      "metadata": {
        "id": "gftXF94U-KdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb5664b-32b0-4d51-e691-c1f79d5bbaa5"
      },
      "id": "gftXF94U-KdL",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 10946\n",
            "                                                   text  label\n",
            "0     nike air force   essential let your shoe game ...    NaN\n",
            "1     nike air force   the legend lives on in the ni...    NaN\n",
            "2     nike air force  sage low lx taking both height...    NaN\n",
            "3     nike air max dia se designed for a womans foot...    NaN\n",
            "4     nike air max verona pass on the good vibes in ...    NaN\n",
            "...                                                 ...    ...\n",
            "9995               nike athletic wear boast fashionable    1.0\n",
            "9996                  nike trousers feature inexpensive    1.0\n",
            "9997                nike soccer shoes feature defective    0.0\n",
            "9998                          nike shoes feature faulty    0.0\n",
            "9999                   asics soccer shoes is breathable    1.0\n",
            "\n",
            "[10946 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_training_and_testing (model, model_save_file_name, data_file_name, epochs):\n",
        "  original_model_outputs = []\n",
        "  retrained_model_outputs = []\n",
        "\n",
        "  for text in TESTING_TEXT:\n",
        "    original_model_outputs.append({\n",
        "      'text': text,\n",
        "      'tokens': top_k_tokens(model, text, TOP_K)\n",
        "    })\n",
        "\n",
        "  retrained_data = retrain_model(model, data_file_name, epochs, model_save_file_name)\n",
        "\n",
        "  for text in TESTING_TEXT:\n",
        "    retrained_model_outputs.append({\n",
        "      'text': text,\n",
        "      'tokens': top_k_tokens(model, text, TOP_K)\n",
        "    })\n",
        "  \n",
        "  return original_model_outputs, retrained_model_outputs, retrained_data\n",
        "\n",
        "def pretty_print_original_vs_retrained_outputs (original_model_outputs, retrained_model_outputs):\n",
        "  for original, retrained in zip(original_model_outputs, retrained_model_outputs):\n",
        "    print('                Text:', original['text'])\n",
        "    print(' Original Top Tokens:', original['tokens'])\n",
        "    print('Retrained Top Tokens:', retrained['tokens'])\n",
        "    print()"
      ],
      "metadata": {
        "id": "skZY5cjwv2B4"
      },
      "id": "skZY5cjwv2B4",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = get_model_and_tokenizer()\n",
        "\n",
        "original_model_outputs, retrained_model_outputs, results_v1 = \\\n",
        "  perform_training_and_testing(model, model_save_file_name + '-v1', synthesized_data_file_name, epochs=5)\n",
        "\n",
        "pretty_print_original_vs_retrained_outputs(original_model_outputs, retrained_model_outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f60b2aaa4c5746b892f907b074710d09",
            "57254250d170460a8556a0f4687d592b",
            "c2cc17333b9a47ccb9226233b1562ae4",
            "be150abb02714870aa203535b020f181",
            "8740c04365794c2ea495dfbf5c5b5c50",
            "6576f5ce7e804f5baa2b43e3abfb1660",
            "4df55b3e74a04bf88a47244b2f444148",
            "28421945a2d0405699f788c6f4a9e133",
            "6f9f6a16a4ed463aa9b8d2131203ba16",
            "4e719f3baf3a49398a56f2a7b5d20fae",
            "efa8812db9174f5db85f85fffcc2b3b8"
          ]
        },
        "id": "rKHXAs12rCcB",
        "outputId": "4219f153-e7a7-427d-d0e2-2d9cbf994741"
      },
      "id": "rKHXAs12rCcB",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForMaskedLM.\n",
            "\n",
            "All the weights of DistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForMaskedLM for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is \"cuda\" available? True\n",
            "Device: Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-e05db79ce3b36267\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/json/default-e05db79ce3b36267/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f60b2aaa4c5746b892f907b074710d09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-e05db79ce3b36267/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-b62d1631d1c3e6ab.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-e05db79ce3b36267/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-15ab7596e6538036.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-e05db79ce3b36267/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-74ad32a978a7ae2e.arrow and /root/.cache/huggingface/datasets/json/default-e05db79ce3b36267/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-efbe71534e38160f.arrow\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 1077\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 85\n",
            "  Number of trainable parameters = 66985530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Training Eval Results:\n",
            " {\n",
            "  \"eval_loss\": 4.67988395690918,\n",
            "  \"eval_runtime\": 0.6466,\n",
            "  \"eval_samples_per_second\": 185.595,\n",
            "  \"eval_steps_per_second\": 3.093\n",
            "}\n",
            "  Before Training Perplexity: 107.76\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='85' max='85' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [85/85 06:17, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.906454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.794898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.563092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.403709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.367691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.418432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.133750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.123809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.939871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.796500</td>\n",
              "      <td>2.811829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>3.796500</td>\n",
              "      <td>2.879576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>3.796500</td>\n",
              "      <td>2.782932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>3.796500</td>\n",
              "      <td>2.783150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>3.796500</td>\n",
              "      <td>2.684983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>3.796500</td>\n",
              "      <td>2.712460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>3.796500</td>\n",
              "      <td>2.625269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>3.796500</td>\n",
              "      <td>2.670328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>3.796500</td>\n",
              "      <td>2.562309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.796500</td>\n",
              "      <td>2.589113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.918900</td>\n",
              "      <td>2.462290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>2.918900</td>\n",
              "      <td>2.547549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>2.918900</td>\n",
              "      <td>2.484078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>2.918900</td>\n",
              "      <td>2.540186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>2.918900</td>\n",
              "      <td>2.481300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>2.918900</td>\n",
              "      <td>2.497803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>2.918900</td>\n",
              "      <td>2.354061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>2.918900</td>\n",
              "      <td>2.446882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>2.918900</td>\n",
              "      <td>2.331486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.918900</td>\n",
              "      <td>2.447801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.651600</td>\n",
              "      <td>2.283267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>2.651600</td>\n",
              "      <td>2.410309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>2.651600</td>\n",
              "      <td>2.386683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>2.651600</td>\n",
              "      <td>2.410392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>2.651600</td>\n",
              "      <td>2.303948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>2.651600</td>\n",
              "      <td>2.326857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>2.651600</td>\n",
              "      <td>2.268485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>2.651600</td>\n",
              "      <td>2.304510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>2.651600</td>\n",
              "      <td>2.265920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.651600</td>\n",
              "      <td>2.319630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.457600</td>\n",
              "      <td>2.287184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>2.457600</td>\n",
              "      <td>2.311465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>2.457600</td>\n",
              "      <td>2.184952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>2.457600</td>\n",
              "      <td>2.280415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>2.457600</td>\n",
              "      <td>2.191885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>2.457600</td>\n",
              "      <td>2.233302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>2.457600</td>\n",
              "      <td>2.330464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>2.457600</td>\n",
              "      <td>2.213836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>2.457600</td>\n",
              "      <td>2.293693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.457600</td>\n",
              "      <td>2.264231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.520800</td>\n",
              "      <td>2.103364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>2.520800</td>\n",
              "      <td>2.262591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>2.520800</td>\n",
              "      <td>2.067529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>2.520800</td>\n",
              "      <td>2.197114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>2.520800</td>\n",
              "      <td>2.236248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>2.520800</td>\n",
              "      <td>2.217484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>2.520800</td>\n",
              "      <td>2.083532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>2.520800</td>\n",
              "      <td>2.195505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>2.520800</td>\n",
              "      <td>2.150660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.520800</td>\n",
              "      <td>2.213557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>2.033566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>2.162340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>2.179227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>2.236513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>2.112682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>2.117802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>2.187187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>2.153264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>2.094286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.297000</td>\n",
              "      <td>2.168890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.307100</td>\n",
              "      <td>2.090604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>2.307100</td>\n",
              "      <td>2.186609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>2.307100</td>\n",
              "      <td>2.189529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>2.307100</td>\n",
              "      <td>2.088351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>2.307100</td>\n",
              "      <td>2.203169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>2.307100</td>\n",
              "      <td>2.179521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>2.307100</td>\n",
              "      <td>2.116023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>2.307100</td>\n",
              "      <td>2.148031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>2.307100</td>\n",
              "      <td>2.146675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.307100</td>\n",
              "      <td>2.205940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.207600</td>\n",
              "      <td>2.092977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>2.207600</td>\n",
              "      <td>2.122165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>2.207600</td>\n",
              "      <td>2.074967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>2.207600</td>\n",
              "      <td>2.186861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>2.207600</td>\n",
              "      <td>2.201152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-10\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-10/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-10/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-10/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-10/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-20\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-20/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-20/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-20/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-20/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-30\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-30/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-30/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-30/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-30/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-40\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-40/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-40/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-40/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-40/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-50\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-50/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-50/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-50/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-50/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-60\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-60/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-60/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-60/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-60/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-70\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-70/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-70/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-70/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-70/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-80\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-80/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-80/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-80/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-80/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1077\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-customer-product-support-v1\n",
            "Configuration saved in distilbert-base-uncased-finetuned-customer-product-support-v1/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-customer-product-support-v1/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-customer-product-support-v1/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-customer-product-support-v1/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 120\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Training Eval Results:\n",
            " {\n",
            "  \"eval_loss\": 1.9603054523468018,\n",
            "  \"eval_runtime\": 0.6531,\n",
            "  \"eval_samples_per_second\": 183.748,\n",
            "  \"eval_steps_per_second\": 3.062,\n",
            "  \"epoch\": 5.0\n",
            "}\n",
            "  After Training Perplexity: 7.10\n",
            "                Text: Nike shoes are very [MASK]\n",
            " Original Top Tokens: ['popular', 'durable', 'expensive', 'comfortable', 'fashionable', 'attractive', 'common', 'effective', 'versatile', 'valuable']\n",
            "Retrained Top Tokens: ['expensive', 'comfortable', 'popular', 'durable', 'fashionable', 'costly', 'lightweight', 'uncomfortable', 'heavy', 'flexible']\n",
            "\n",
            "                Text: Nike atheletic wear is known for being very [MASK]\n",
            " Original Top Tokens: ['durable', 'expensive', 'popular', 'fashionable', 'rare', 'sharp', 'strong', 'distinctive', 'elastic', 'attractive']\n",
            "Retrained Top Tokens: ['durable', 'expensive', 'costly', 'fashionable', 'heavy', 'lightweight', 'flexible', 'innovative', 'athletic', 'popular']\n",
            "\n",
            "                Text: Nike [MASK] shoes are very comfortable\n",
            " Original Top Tokens: ['polo', 'golf', 'swim', 'tennis', 'nike', 'shoe', 'sports', 'basketball', 'athletic', 'skate']\n",
            "Retrained Top Tokens: ['basketball', 'soccer', 'training', 'running', 'football', 'golf', 'tennis', 'gym', 'polo', 'athletic']\n",
            "\n",
            "                Text: Trousers and Hoodies made by [MASK] are not very expensive\n",
            " Original Top Tokens: ['women', 'manufacturers', 'men', 'amateurs', 'slaves', 'consumers', 'collectors', 'europeans', 'farmers', 'artisans']\n",
            "Retrained Top Tokens: ['men', 'women', 'manufacturers', 'consumers', 'amateurs', 'hand', 'collectors', 'people', 'workers', 'individuals']\n",
            "\n",
            "                Text: Nike tshirts are famous for being [MASK]\n",
            " Original Top Tokens: ['.', ':', ';', 'colorful', 'unique', '!', 'famous', 'tall', 'popular', 'green']\n",
            "Retrained Top Tokens: ['lightweight', 'durable', 'innovative', 'inexpensive', 'athletic', 'expensive', 'costly', 'fashionable', 'ugly', 'comfortable']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QFpsGxx_4N0Y"
      },
      "outputs": [],
      "source": [
        "vader_sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def nike_text_present_func (inputs, outputs, gts=None, extra_args={}):\n",
        "  is_present = []\n",
        "  for input in inputs[\"text\"]:\n",
        "    is_present.append(bool(\"nike\" in input.lower()))\n",
        "  return is_present\n",
        "\n",
        "def nike_product_keyword_func (inputs, outputs, gts=None, extra_args={}):\n",
        "  is_present = []\n",
        "  for input in inputs[\"text\"]:\n",
        "    input = input.lower()\n",
        "    for word in PRODUCTS:\n",
        "      if word in input:\n",
        "        is_present.append(True)\n",
        "        break\n",
        "    else:\n",
        "      is_present.append(False)\n",
        "  return is_present\n",
        "\n",
        "def is_positive_sentiment_func (inputs, outputs, gts=None, extra_args={}):\n",
        "  is_positive = []\n",
        "  for input in inputs[\"text\"]:\n",
        "    input = input.lower()\n",
        "    positive = False\n",
        "    \n",
        "    if vader_sia.polarity_scores(input)[\"compound\"] >= 0:\n",
        "      for word in PRODUCT_FEATURE_WORDS:\n",
        "        if word in input:\n",
        "          positive = True\n",
        "          break\n",
        "    \n",
        "    is_positive.append(positive)\n",
        "  \n",
        "  return is_positive\n",
        "\n",
        "def content_length_func (inputs, outputs, gts=None, extra_args={}):\n",
        "  lengths = []\n",
        "  for input in inputs[\"text\"]:\n",
        "    lengths.append(len(input))\n",
        "  return lengths"
      ],
      "id": "QFpsGxx_4N0Y"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "d9edc5da-8366-4c55-93a7-4601c89c9970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e506b413-4f2c-4dab-d59f-b625badcb272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting the folder:  uptrain_smart_data_bert\n"
          ]
        }
      ],
      "source": [
        "cfg = {\n",
        "    'checks': [\n",
        "      {\n",
        "        'type': uptrain.Anomaly.EDGE_CASE,\n",
        "        \"signal_formulae\": \\\n",
        "          uptrain.Signal(\"'Nike' text Present\", nike_text_present_func) &\n",
        "          uptrain.Signal(\"Is it a Nike product\", nike_product_keyword_func) &\n",
        "          uptrain.Signal(\"Is positive Sentiment\", is_positive_sentiment_func)\n",
        "      },\n",
        "\n",
        "      {\n",
        "        'type': uptrain.Anomaly.DATA_INTEGRITY,\n",
        "        'measurable_args': {\n",
        "          'type': uptrain.MeasurableType.INPUT_FEATURE,\n",
        "          'feature_name': 'text'\n",
        "        },\n",
        "        'integrity_type': 'non_null'\n",
        "      },\n",
        "\n",
        "      {\n",
        "        'type': uptrain.Anomaly.DATA_INTEGRITY,\n",
        "        'measurable_args': {\n",
        "          'type': uptrain.MeasurableType.CUSTOM,\n",
        "          'signal_formulae': uptrain.Signal(\"content_length\", content_length_func),\n",
        "        },\n",
        "        \"integrity_type\": \"greater_than\",\n",
        "        \"threshold\": 256\n",
        "      },\n",
        "\n",
        "      {\n",
        "        'type': uptrain.Anomaly.CONCEPT_DRIFT,\n",
        "        'algorithm': uptrain.DataDriftAlgo.DDM\n",
        "      }\n",
        "    ],\n",
        "\n",
        "    # Define where to save the retraining dataset\n",
        "    'retraining_folder': uptrain_save_fold_name,\n",
        "    \n",
        "    # Define when to retrain, define a large number because we\n",
        "    # are not retraining yet\n",
        "    'retrain_after': 10000000000\n",
        "}\n",
        "\n",
        "framework = uptrain.Framework(cfg)"
      ],
      "id": "d9edc5da-8366-4c55-93a7-4601c89c9970"
    },
    {
      "cell_type": "code",
      "source": [
        "for index, sample in enumerate(dataset['data']):\n",
        "  if index % 500 == 0:\n",
        "    print(f'Processed {index} samples')\n",
        "  inputs = {'data': {'text': [sample['text']]}}\n",
        "  framework.log(inputs = inputs, outputs = None)\n",
        "\n",
        "retraining_csv = uptrain_save_fold_name + '/1/smart_data.csv'\n",
        "retraining_json = 'retrain_dataset.json'\n",
        "create_dataset_from_csv(retraining_csv, 'text', retraining_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RTj4jA1ipOS0",
        "outputId": "ce461f98-8c1e-4350-89c2-21c8809daf31"
      },
      "id": "RTj4jA1ipOS0",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0 samples\n",
            "Processed 500 samples\n",
            "50  edge cases identified out of  826  total samples\n",
            "Processed 1000 samples\n",
            "100  edge cases identified out of  1099  total samples\n",
            "150  edge cases identified out of  1274  total samples\n",
            "200  edge cases identified out of  1492  total samples\n",
            "Processed 1500 samples\n",
            "250  edge cases identified out of  1669  total samples\n",
            "300  edge cases identified out of  1849  total samples\n",
            "Processed 2000 samples\n",
            "350  edge cases identified out of  2025  total samples\n",
            "400  edge cases identified out of  2198  total samples\n",
            "450  edge cases identified out of  2367  total samples\n",
            "Processed 2500 samples\n",
            "500  edge cases identified out of  2507  total samples\n",
            "550  edge cases identified out of  2740  total samples\n",
            "600  edge cases identified out of  2899  total samples\n",
            "Processed 3000 samples\n",
            "650  edge cases identified out of  3095  total samples\n",
            "700  edge cases identified out of  3261  total samples\n",
            "750  edge cases identified out of  3428  total samples\n",
            "Processed 3500 samples\n",
            "800  edge cases identified out of  3617  total samples\n",
            "850  edge cases identified out of  3809  total samples\n",
            "Processed 4000 samples\n",
            "900  edge cases identified out of  4040  total samples\n",
            "950  edge cases identified out of  4242  total samples\n",
            "1000  edge cases identified out of  4453  total samples\n",
            "Processed 4500 samples\n",
            "1050  edge cases identified out of  4660  total samples\n",
            "1100  edge cases identified out of  4805  total samples\n",
            "1150  edge cases identified out of  4967  total samples\n",
            "Processed 5000 samples\n",
            "1200  edge cases identified out of  5140  total samples\n",
            "1250  edge cases identified out of  5315  total samples\n",
            "1300  edge cases identified out of  5476  total samples\n",
            "Processed 5500 samples\n",
            "1350  edge cases identified out of  5662  total samples\n",
            "1400  edge cases identified out of  5845  total samples\n",
            "Processed 6000 samples\n",
            "1450  edge cases identified out of  6019  total samples\n",
            "1500  edge cases identified out of  6249  total samples\n",
            "1550  edge cases identified out of  6467  total samples\n",
            "Processed 6500 samples\n",
            "1600  edge cases identified out of  6705  total samples\n",
            "1650  edge cases identified out of  6919  total samples\n",
            "Processed 7000 samples\n",
            "1700  edge cases identified out of  7092  total samples\n",
            "1750  edge cases identified out of  7312  total samples\n",
            "1800  edge cases identified out of  7481  total samples\n",
            "Processed 7500 samples\n",
            "1850  edge cases identified out of  7653  total samples\n",
            "1900  edge cases identified out of  7814  total samples\n",
            "1950  edge cases identified out of  7959  total samples\n",
            "Processed 8000 samples\n",
            "2000  edge cases identified out of  8157  total samples\n",
            "2050  edge cases identified out of  8354  total samples\n",
            "Processed 8500 samples\n",
            "2100  edge cases identified out of  8525  total samples\n",
            "2150  edge cases identified out of  8662  total samples\n",
            "2200  edge cases identified out of  8854  total samples\n",
            "Processed 9000 samples\n",
            "2250  edge cases identified out of  9046  total samples\n",
            "2300  edge cases identified out of  9206  total samples\n",
            "2350  edge cases identified out of  9398  total samples\n",
            "Processed 9500 samples\n",
            "2400  edge cases identified out of  9595  total samples\n",
            "2450  edge cases identified out of  9762  total samples\n",
            "2500  edge cases identified out of  9919  total samples\n",
            "Processed 10000 samples\n",
            "2550  edge cases identified out of  10100  total samples\n",
            "2600  edge cases identified out of  10284  total samples\n",
            "2650  edge cases identified out of  10425  total samples\n",
            "Processed 10500 samples\n",
            "2700  edge cases identified out of  10588  total samples\n",
            "2750  edge cases identified out of  10768  total samples\n",
            "2800  edge cases identified out of  10942  total samples\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'retrain_dataset.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = get_model_and_tokenizer()\n",
        "\n",
        "original_model_outputs, retrained_model_outputs, results_v2 = \\\n",
        "  perform_training_and_testing(model, model_save_file_name + '-v2', retraining_json, epochs=25)\n",
        "\n",
        "pretty_print_original_vs_retrained_outputs(original_model_outputs, retrained_model_outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "eb31379cdda643ceaef2643988cf1473",
            "e2afde29182146e4a8defbd2ec88f5ed",
            "9fb5132cff77484588f253c5e3afd4f3",
            "9297a27849f14ff49b3c957d3b5f9ff3",
            "7b1a95d7033842768ad7990dc2a4ad15",
            "8ac208eadfea428bba8d48cae505b390",
            "6c7603a1f7bc4ce7b3c70ff9c62c07de",
            "2d59db5afaca4e49a2fa8d9a0bab869e",
            "64b1e81f87da4851bdf2cba08f7c3ae1",
            "dfa98426bf9c4b3ca5cc2d3b5409a6e7",
            "5b9681f8698b453badf1dc4c515c6390"
          ]
        },
        "id": "KEAyopivtTCj",
        "outputId": "4ef54440-e3f6-44aa-8492-395a018bda9f"
      },
      "id": "KEAyopivtTCj",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForMaskedLM.\n",
            "\n",
            "All the weights of DistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForMaskedLM for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is \"cuda\" available? True\n",
            "Device: Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-bff99c7f060de33d\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/json/default-bff99c7f060de33d/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb31379cdda643ceaef2643988cf1473"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-bff99c7f060de33d/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-b07a36bde871a336.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-bff99c7f060de33d/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-1cf1e7f3149b77bd.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-bff99c7f060de33d/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-b19f16d7fecade52.arrow and /root/.cache/huggingface/datasets/json/default-bff99c7f060de33d/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-ec00234d55668499.arrow\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 211\n",
            "  Num Epochs = 25\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 100\n",
            "  Number of trainable parameters = 66985530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Training Eval Results:\n",
            " {\n",
            "  \"eval_loss\": 4.28580379486084,\n",
            "  \"eval_runtime\": 0.2035,\n",
            "  \"eval_samples_per_second\": 117.927,\n",
            "  \"eval_steps_per_second\": 4.914\n",
            "}\n",
            "  Before Training Perplexity: 72.66\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 02:56, Epoch 25/25]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.147176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.157563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.647243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.474576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.325419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.410182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.184188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.150027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.057662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.947100</td>\n",
              "      <td>2.098443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.947100</td>\n",
              "      <td>1.920464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.947100</td>\n",
              "      <td>1.633115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.947100</td>\n",
              "      <td>1.872063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.947100</td>\n",
              "      <td>1.817776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>2.947100</td>\n",
              "      <td>1.692934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>2.947100</td>\n",
              "      <td>1.582809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.947100</td>\n",
              "      <td>1.646172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.947100</td>\n",
              "      <td>1.419270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.947100</td>\n",
              "      <td>1.627537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.930800</td>\n",
              "      <td>1.446132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.930800</td>\n",
              "      <td>1.542318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.930800</td>\n",
              "      <td>1.531590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.930800</td>\n",
              "      <td>1.534183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.930800</td>\n",
              "      <td>1.397494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.930800</td>\n",
              "      <td>1.500994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.930800</td>\n",
              "      <td>1.405550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.930800</td>\n",
              "      <td>1.462018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.930800</td>\n",
              "      <td>1.294410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.930800</td>\n",
              "      <td>1.413673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.523000</td>\n",
              "      <td>1.193972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.523000</td>\n",
              "      <td>1.395025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.523000</td>\n",
              "      <td>1.190265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.523000</td>\n",
              "      <td>1.394809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.523000</td>\n",
              "      <td>1.196266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.523000</td>\n",
              "      <td>1.360099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.523000</td>\n",
              "      <td>1.137417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.523000</td>\n",
              "      <td>1.413960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.523000</td>\n",
              "      <td>1.227489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.523000</td>\n",
              "      <td>1.306377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.495100</td>\n",
              "      <td>1.330730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.495100</td>\n",
              "      <td>1.304744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.495100</td>\n",
              "      <td>1.270455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.495100</td>\n",
              "      <td>1.335589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.495100</td>\n",
              "      <td>1.054317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.495100</td>\n",
              "      <td>1.323245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.495100</td>\n",
              "      <td>1.257087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.495100</td>\n",
              "      <td>1.251856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.495100</td>\n",
              "      <td>1.099582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.495100</td>\n",
              "      <td>1.316326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.414700</td>\n",
              "      <td>1.236999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.414700</td>\n",
              "      <td>1.266353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.414700</td>\n",
              "      <td>1.258130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.414700</td>\n",
              "      <td>1.259095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.414700</td>\n",
              "      <td>1.236990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.414700</td>\n",
              "      <td>1.233764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.414700</td>\n",
              "      <td>1.093983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.414700</td>\n",
              "      <td>1.273698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.414700</td>\n",
              "      <td>1.262611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.414700</td>\n",
              "      <td>1.235675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.322100</td>\n",
              "      <td>1.103125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.322100</td>\n",
              "      <td>1.281175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.322100</td>\n",
              "      <td>1.127905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.322100</td>\n",
              "      <td>1.200191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.322100</td>\n",
              "      <td>0.986747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.322100</td>\n",
              "      <td>1.223667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.322100</td>\n",
              "      <td>1.291668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.322100</td>\n",
              "      <td>1.229317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.322100</td>\n",
              "      <td>1.012321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.322100</td>\n",
              "      <td>1.193984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.333100</td>\n",
              "      <td>1.217290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.333100</td>\n",
              "      <td>1.218089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.333100</td>\n",
              "      <td>1.024908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.333100</td>\n",
              "      <td>1.270605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.333100</td>\n",
              "      <td>0.988525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.333100</td>\n",
              "      <td>1.245821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.333100</td>\n",
              "      <td>0.962317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.333100</td>\n",
              "      <td>1.227178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.333100</td>\n",
              "      <td>1.019317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.333100</td>\n",
              "      <td>1.221552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.306000</td>\n",
              "      <td>1.212229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.306000</td>\n",
              "      <td>1.296641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.306000</td>\n",
              "      <td>0.856489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.306000</td>\n",
              "      <td>1.168833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.306000</td>\n",
              "      <td>1.095096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.306000</td>\n",
              "      <td>1.183473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.306000</td>\n",
              "      <td>1.007826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.306000</td>\n",
              "      <td>1.213391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.306000</td>\n",
              "      <td>0.928230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.306000</td>\n",
              "      <td>1.227610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.271100</td>\n",
              "      <td>1.081334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.271100</td>\n",
              "      <td>1.145511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.271100</td>\n",
              "      <td>1.044742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.271100</td>\n",
              "      <td>1.217075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.271100</td>\n",
              "      <td>1.097147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.271100</td>\n",
              "      <td>1.262752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.271100</td>\n",
              "      <td>1.007061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>1.271100</td>\n",
              "      <td>1.166071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>1.271100</td>\n",
              "      <td>0.962977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.271100</td>\n",
              "      <td>1.133080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.326600</td>\n",
              "      <td>1.093500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-10\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-10/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-10/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-10/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-10/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-20\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-20/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-20/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-20/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-20/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-30\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-30/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-30/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-30/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-30/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-40\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-40/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-40/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-40/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-40/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-50\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-50/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-50/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-50/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-50/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-60\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-60/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-60/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-60/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-60/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-70\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-70/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-70/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-70/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-70/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-80\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-80/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-80/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-80/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-80/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-90\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-90/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-90/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 211\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-uptrain/checkpoint-100\n",
            "Configuration saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-100/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-100/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-100/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-uptrain/checkpoint-100/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-customer-product-support-v2\n",
            "Configuration saved in distilbert-base-uncased-finetuned-customer-product-support-v2/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-customer-product-support-v2/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-customer-product-support-v2/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-customer-product-support-v2/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `DistilBertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Training Eval Results:\n",
            " {\n",
            "  \"eval_loss\": 0.9722399115562439,\n",
            "  \"eval_runtime\": 0.2044,\n",
            "  \"eval_samples_per_second\": 117.426,\n",
            "  \"eval_steps_per_second\": 4.893,\n",
            "  \"epoch\": 25.0\n",
            "}\n",
            "  After Training Perplexity: 2.64\n",
            "                Text: Nike shoes are very [MASK]\n",
            " Original Top Tokens: ['popular', 'durable', 'expensive', 'comfortable', 'fashionable', 'attractive', 'common', 'effective', 'versatile', 'valuable']\n",
            "Retrained Top Tokens: ['comfortable', 'expensive', 'fashionable', 'popular', 'durable', 'flexible', 'athletic', 'modern', 'lightweight', 'cheap']\n",
            "\n",
            "                Text: Nike atheletic wear is known for being very [MASK]\n",
            " Original Top Tokens: ['durable', 'expensive', 'popular', 'fashionable', 'rare', 'sharp', 'strong', 'distinctive', 'elastic', 'attractive']\n",
            "Retrained Top Tokens: ['durable', 'flexible', 'lightweight', 'fashionable', 'athletic', 'innovative', 'expensive', 'revolutionary', 'comfortable', 'modern']\n",
            "\n",
            "                Text: Nike [MASK] shoes are very comfortable\n",
            " Original Top Tokens: ['polo', 'golf', 'swim', 'tennis', 'nike', 'shoe', 'sports', 'basketball', 'athletic', 'skate']\n",
            "Retrained Top Tokens: ['basketball', 'soccer', 'training', 'running', 'football', 'tennis', 'gym', 'athletic', 'performance', 'sports']\n",
            "\n",
            "                Text: Trousers and Hoodies made by [MASK] are not very expensive\n",
            " Original Top Tokens: ['women', 'manufacturers', 'men', 'amateurs', 'slaves', 'consumers', 'collectors', 'europeans', 'farmers', 'artisans']\n",
            "Retrained Top Tokens: ['men', 'manufacturers', 'women', 'amateurs', 'consumers', 'collectors', 'workers', 'hand', 'craftsmen', 'professionals']\n",
            "\n",
            "                Text: Nike tshirts are famous for being [MASK]\n",
            " Original Top Tokens: ['.', ':', ';', 'colorful', 'unique', '!', 'famous', 'tall', 'popular', 'green']\n",
            "Retrained Top Tokens: ['lightweight', 'durable', 'flexible', 'inexpensive', 'athletic', 'modern', 'innovative', 'revolutionary', 'comfortable', 'functional']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_history (log_history):\n",
        "  training_loss_history = []\n",
        "  training_loss_steps = []\n",
        "  eval_loss_history = []\n",
        "  eval_loss_steps = []\n",
        "  \n",
        "  for history in log_history[:-2]:\n",
        "    if 'train_loss' in history.keys():\n",
        "      training_loss_history.append(history['train_loss'])\n",
        "      training_loss_steps.append(history['step'])\n",
        "    if 'eval_loss' in history.keys():\n",
        "      eval_loss_history.append(history['eval_loss'])\n",
        "      eval_loss_steps.append(history['step'])\n",
        "  \n",
        "  return (training_loss_steps, training_loss_history), (eval_loss_steps, eval_loss_history)\n",
        "\n",
        "def get_perplexities (eval_loss_history):\n",
        "  return list(map(math.exp, eval_loss_history))"
      ],
      "metadata": {
        "id": "CMWiVL7qVRYx"
      },
      "id": "CMWiVL7qVRYx",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_v1 = results_v1[-1]\n",
        "trainer_v2 = results_v2[-1]\n",
        "\n",
        "v1_training_history, v1_eval_history = get_loss_history(trainer_v1.state.log_history)\n",
        "v2_training_history, v2_eval_history = get_loss_history(trainer_v2.state.log_history)\n",
        "\n",
        "v1_perplexities = get_perplexities(v1_eval_history[1])\n",
        "v2_perplexities = get_perplexities(v2_eval_history[1])"
      ],
      "metadata": {
        "id": "I-rtSl60i8h6"
      },
      "id": "I-rtSl60i8h6",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with plt.style.context('fivethirtyeight'):\n",
        "  fig, axs = plt.subplots(2, 1, sharex = True)\n",
        "\n",
        "  fig.set_size_inches(12, 8)\n",
        "  fig.suptitle('Loss/Perplexity over Time', fontsize = 20)\n",
        "  fig.supxlabel('Steps')\n",
        "  fig.supylabel('Loss')\n",
        "\n",
        "  axs[0].set_title('Model Trained on Full Dataset')\n",
        "  axs[1].set_title('Model Trained on UpTrain Retrain Dataset')\n",
        "\n",
        "  training_color = 'green'\n",
        "  validation_color = 'red'\n",
        "  axs[0].plot(*v1_training_history, label = 'Training', color = training_color)\n",
        "  axs[0].plot(*v1_eval_history, label = 'Validation', color = validation_color)\n",
        "  axs[1].plot(*v2_training_history, label = 'Training', color = training_color)\n",
        "  axs[1].plot(*v2_eval_history, label = 'Validation', color = validation_color)\n",
        "\n",
        "  color = 'purple'\n",
        "  axs0twin = axs[0].twinx()\n",
        "  axs0twin.set_ylabel('Perplexity', fontsize = 10, color = color)\n",
        "  axs0twin.plot(v1_eval_history[0], v1_perplexities, label = 'Perplexity', color = color)\n",
        "  axs0twin.tick_params(axis='y', color = color)\n",
        "\n",
        "  axs1twin = axs[1].twinx()\n",
        "  axs1twin.set_ylabel('Perplexity', fontsize = 10, color = color)\n",
        "  axs1twin.plot(v2_eval_history[0], v2_perplexities, label = 'Perplexity', color = color)\n",
        "  axs1twin.tick_params(axis='y', color = color)\n",
        "\n",
        "  axs[0].legend()\n",
        "  axs[1].legend()\n",
        "\n",
        "  fig.subplots_adjust(top=1)\n",
        "  fig.tight_layout()\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "Cls1xNZ4cPLO",
        "outputId": "649a2c6b-2a0d-4893-b2d5-2d3528fccb39"
      },
      "id": "Cls1xNZ4cPLO",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pIt56E6SLROs"
      },
      "id": "pIt56E6SLROs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/uptrain\n",
        "!ls"
      ],
      "metadata": {
        "id": "C4qFxjVFLdKt"
      },
      "id": "C4qFxjVFLdKt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r data.csv distilbert-base-uncased-finetuned-uptrain distilbert-base-uncased-finetuned-customer-product-support-v1 distilbert-base-uncased-finetuned-customer-product-support-v2 uptrain_smart_data_bert data.json datasets retrain_dataset.json /content/drive/MyDrive/uptrain"
      ],
      "metadata": {
        "id": "-ycceE10L7Lw"
      },
      "id": "-ycceE10L7Lw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/course/chapter7/3\n",
        "\n",
        "# retrain_dataset = load_dataset('json', data_files={\"train\": synthesized_data_file_name}, field='data')\n",
        "# tokenized_datasets = retrain_dataset.map(\n",
        "#   tokenize_function, batched=True, remove_columns=[\"text\", \"label\"]\n",
        "# )\n",
        "\n",
        "# lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
        "# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=mlm_probability)\n",
        "\n",
        "# downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
        "#   train_size=train_size, test_size=test_size,# seed=42\n",
        "# )\n",
        "\n",
        "# # Show the training loss with every epoch\n",
        "# logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
        "\n",
        "# def insert_random_mask(batch):\n",
        "#   features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
        "#   masked_inputs = data_collator(features)\n",
        "#   return {\"masked_\" + k: v.numpy() for k, v in masked_inputs.items()}\n",
        "\n",
        "# downsampled_dataset = downsampled_dataset.remove_columns([\"word_ids\"])\n",
        "# eval_dataset = downsampled_dataset[\"test\"].map(\n",
        "#     insert_random_mask,\n",
        "#     batched=True,\n",
        "#     remove_columns=downsampled_dataset[\"test\"].column_names,\n",
        "# )\n",
        "# eval_dataset = eval_dataset.rename_columns(\n",
        "#   {\n",
        "#     \"masked_input_ids\": \"input_ids\",\n",
        "#     \"masked_attention_mask\": \"attention_mask\",\n",
        "#     \"masked_labels\": \"labels\",\n",
        "#   }\n",
        "# )\n",
        "\n",
        "# train_dataloader = DataLoader(\n",
        "#   downsampled_dataset[\"train\"],\n",
        "#   shuffle=True,\n",
        "#   batch_size=batch_size,\n",
        "#   collate_fn=data_collator,\n",
        "# )\n",
        "# eval_dataloader = DataLoader(\n",
        "#   eval_dataset, batch_size=batch_size, collate_fn=default_data_collator\n",
        "# )\n",
        "\n",
        "# optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# accelerator = Accelerator()\n",
        "# model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "#   model, optimizer, train_dataloader, eval_dataloader\n",
        "# )\n",
        "\n",
        "# num_train_epochs = 5\n",
        "# num_update_steps_per_epoch = len(train_dataloader)\n",
        "# num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "# lr_scheduler = get_scheduler(\n",
        "#   \"linear\",\n",
        "#   optimizer=optimizer,\n",
        "#   num_warmup_steps=0,\n",
        "#   num_training_steps=num_training_steps,\n",
        "# )\n",
        "\n",
        "# progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "# for epoch in range(num_train_epochs):\n",
        "#     # Training\n",
        "#     model.train()\n",
        "#     for batch in train_dataloader:\n",
        "#         outputs = model(**batch)\n",
        "#         loss = outputs.loss\n",
        "#         accelerator.backward(loss)\n",
        "\n",
        "#         optimizer.step()\n",
        "#         lr_scheduler.step()\n",
        "#         optimizer.zero_grad()\n",
        "#         progress_bar.update(1)\n",
        "\n",
        "#     # Evaluation\n",
        "#     model.eval()\n",
        "#     losses = []\n",
        "#     for step, batch in enumerate(eval_dataloader):\n",
        "#         with torch.no_grad():\n",
        "#             outputs = model(**batch)\n",
        "\n",
        "#         loss = outputs.loss\n",
        "#         losses.append(accelerator.gather(loss.repeat(batch_size)))\n",
        "\n",
        "#     losses = torch.cat(losses)\n",
        "#     losses = losses[: len(eval_dataset)]\n",
        "#     try:\n",
        "#         perplexity = math.exp(torch.mean(losses))\n",
        "#     except OverflowError:\n",
        "#         perplexity = float(\"inf\")\n",
        "\n",
        "#     print(f\">>> Epoch {epoch}, Perplexity: {perplexity}\")\n",
        "\n",
        "#     accelerator.wait_for_everyone()\n",
        "#     unwrapped_model = accelerator.unwrap_model(model)\n",
        "#     unwrapped_model.save_pretrained(uptrain_save_fold_name, save_function=accelerator.save)\n",
        "#     if accelerator.is_main_process:\n",
        "#         tokenizer.save_pretrained(uptrain_save_fold_name)"
      ],
      "metadata": {
        "id": "hpsh_0BufU3s"
      },
      "id": "hpsh_0BufU3s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abe66970-c0ce-421d-9f7a-845453615903"
      },
      "outputs": [],
      "source": [
        "# for index, sample in enumerate(all_data['data']):\n",
        "#   if index % 250 == 0:\n",
        "#     print(f'Sample: {index}')\n",
        "#   inputs = {'data': {'text': [sample['text']]}}\n",
        "#   framework.log(inputs = inputs, outputs = None)\n",
        "\n",
        "# retraining_csv = uptrain_save_fold_name + '/1/smart_data.csv'\n",
        "# retraining_json = 'retrain_dataset.json'\n",
        "# csv2json(retraining_csv, retraining_json)"
      ],
      "id": "abe66970-c0ce-421d-9f7a-845453615903"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca8d91d9-4540-4850-ad27-69fe9468e7dc"
      },
      "outputs": [],
      "source": [
        "# retrain_model(model, retraining_dataset)\n",
        "# retrained_model_outputs = test_model(model, testing_text)"
      ],
      "id": "ca8d91d9-4540-4850-ad27-69fe9468e7dc"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XS3C5Mk1_5N0"
      },
      "id": "XS3C5Mk1_5N0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f60b2aaa4c5746b892f907b074710d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57254250d170460a8556a0f4687d592b",
              "IPY_MODEL_c2cc17333b9a47ccb9226233b1562ae4",
              "IPY_MODEL_be150abb02714870aa203535b020f181"
            ],
            "layout": "IPY_MODEL_8740c04365794c2ea495dfbf5c5b5c50",
            "tabbable": null,
            "tooltip": null
          }
        },
        "57254250d170460a8556a0f4687d592b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6576f5ce7e804f5baa2b43e3abfb1660",
            "placeholder": "​",
            "style": "IPY_MODEL_4df55b3e74a04bf88a47244b2f444148",
            "tabbable": null,
            "tooltip": null,
            "value": "100%"
          }
        },
        "c2cc17333b9a47ccb9226233b1562ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_28421945a2d0405699f788c6f4a9e133",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f9f6a16a4ed463aa9b8d2131203ba16",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "be150abb02714870aa203535b020f181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4e719f3baf3a49398a56f2a7b5d20fae",
            "placeholder": "​",
            "style": "IPY_MODEL_efa8812db9174f5db85f85fffcc2b3b8",
            "tabbable": null,
            "tooltip": null,
            "value": " 1/1 [00:00&lt;00:00, 48.01it/s]"
          }
        },
        "8740c04365794c2ea495dfbf5c5b5c50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6576f5ce7e804f5baa2b43e3abfb1660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df55b3e74a04bf88a47244b2f444148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "28421945a2d0405699f788c6f4a9e133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f9f6a16a4ed463aa9b8d2131203ba16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e719f3baf3a49398a56f2a7b5d20fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efa8812db9174f5db85f85fffcc2b3b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "eb31379cdda643ceaef2643988cf1473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2afde29182146e4a8defbd2ec88f5ed",
              "IPY_MODEL_9fb5132cff77484588f253c5e3afd4f3",
              "IPY_MODEL_9297a27849f14ff49b3c957d3b5f9ff3"
            ],
            "layout": "IPY_MODEL_7b1a95d7033842768ad7990dc2a4ad15",
            "tabbable": null,
            "tooltip": null
          }
        },
        "e2afde29182146e4a8defbd2ec88f5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8ac208eadfea428bba8d48cae505b390",
            "placeholder": "​",
            "style": "IPY_MODEL_6c7603a1f7bc4ce7b3c70ff9c62c07de",
            "tabbable": null,
            "tooltip": null,
            "value": "100%"
          }
        },
        "9fb5132cff77484588f253c5e3afd4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2d59db5afaca4e49a2fa8d9a0bab869e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64b1e81f87da4851bdf2cba08f7c3ae1",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "9297a27849f14ff49b3c957d3b5f9ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_dfa98426bf9c4b3ca5cc2d3b5409a6e7",
            "placeholder": "​",
            "style": "IPY_MODEL_5b9681f8698b453badf1dc4c515c6390",
            "tabbable": null,
            "tooltip": null,
            "value": " 1/1 [00:00&lt;00:00, 55.98it/s]"
          }
        },
        "7b1a95d7033842768ad7990dc2a4ad15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ac208eadfea428bba8d48cae505b390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c7603a1f7bc4ce7b3c70ff9c62c07de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "2d59db5afaca4e49a2fa8d9a0bab869e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b1e81f87da4851bdf2cba08f7c3ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfa98426bf9c4b3ca5cc2d3b5409a6e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9681f8698b453badf1dc4c515c6390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}